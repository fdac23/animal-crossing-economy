{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stardew Valley Wiki scraping tool\n",
    "\n",
    "This code scrapes the official Stardew Valley wiki for all of the fruits, veggies, and fish. It then performs some data cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "req = requests.get('https://stardewvalleywiki.com/Fruits')\n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "# Matches out the fruit name from the <a> tag\n",
    "pattern = r'<a href=\"/(\\w*(?:\\s\\w*)?)\" title=\"\\1\">\\1</a>'\n",
    "\n",
    "# Isolate the big table at the start of the page\n",
    "table = soup.find_all('table', class_ = 'wikitable')[0].tbody\n",
    "\n",
    "fruitlist = []\n",
    "# Loop over the rows of the table non-recursively, skipping the first two as they're just table metadata\n",
    "for row in table.find_all('tr', recursive = False)[2:]:\n",
    "    # Isolate the table data element, which contains a single <a> tag\n",
    "    fruit = row.find_all('td', recursive = False)[1]\n",
    "    # Pick out the <a> tag, convert it to a string, and replace the potential \"_\" in it (from the wiki URL) with a space for Regex ease\n",
    "    fruit = fruit.a.__str__().replace('_', ' ')\n",
    "    # Take the Regex match out, getting our fruit name!\n",
    "    fruit = re.search(pattern, fruit).group(1)\n",
    "    print(fruit)\n",
    "    fruitlist.append(fruit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get('https://stardewvalleywiki.com/Vegetables')\n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "# Matches out the veg name from the <a> tag\n",
    "pattern = r'<a href=\"/(\\w*(?:\\s\\w*)?)\" title=\"\\1\">\\1</a>'\n",
    "\n",
    "# Isolate the big table at the start of the page\n",
    "table = soup.find_all('table', class_ = 'wikitable')[0].tbody\n",
    "\n",
    "veglist = []\n",
    "# Loop over the rows of the table non-recursively, skipping the first two as they're just table metadata\n",
    "for row in table.find_all('tr', recursive = False)[2:]:\n",
    "    # Isolate the table data element, which contains a single <a> tag\n",
    "    veg = row.find_all('td', recursive = False)[1]\n",
    "    # Pick out the <a> tag, convert it to a string, and replace the potential \"_\" in it (from the wiki URL) with a space for Regex ease\n",
    "    veg = veg.a.__str__().replace('_', ' ')\n",
    "    # Take the Regex match out, getting our veg name!\n",
    "    veg = re.search(pattern, veg).group(1)\n",
    "    print(veg)\n",
    "    veglist.append(veg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get('https://stardewvalleywiki.com/Fish')\n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "# Matches out the fish name from the <a> tag\n",
    "pattern = r'<a href=\"/(\\w*(?:\\s\\w*)?)\" title=\"\\1\">\\1</a>'\n",
    "\n",
    "# Isolate the big table at the start of the page\n",
    "table = soup.find_all('table', class_ = 'wikitable')[0].tbody\n",
    "\n",
    "fishlist = []\n",
    "# Loop over the rows of the table non-recursively, skipping the first two as they're just table metadata\n",
    "for row in table.find_all('tr', recursive = False)[2:]:\n",
    "    # Isolate the table data element, which contains a single <a> tag\n",
    "    fish = row.find_all('td', recursive = False)[1]\n",
    "    # Pick out the <a> tag, convert it to a string, and replace the potential \"_\" in it (from the wiki URL) with a space for Regex ease\n",
    "    fish = fish.a.__str__().replace('_', ' ')\n",
    "    # Take the Regex match out, getting our fish name!\n",
    "    fish = re.search(pattern, fish).group(1)\n",
    "    print(fish)\n",
    "    fishlist.append(fish)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got all our three lists of fruits, veggies, and fish in Stardew. Let's get parsing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruitraw = []\n",
    "for fruit in fruitlist:\n",
    "    fruitraw.append((fruit, BeautifulSoup(requests.get(f'https://stardewvalleywiki.com/{fruit.replace(\" \", \"_\")}').text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruitdata = []\n",
    "for name, fruit in fruitraw:\n",
    "    values = {}\n",
    "    values['name'] = name\n",
    "\n",
    "    table = fruit.find_all('table', {'id': 'infoboxtable'})[0].tbody\n",
    "    rows = table.find_all('tr', recursive = False)\n",
    "\n",
    "    offset = 0\n",
    "    while True:\n",
    "        try:\n",
    "            t1 = rows[9 + offset].find_all('td', recursive = False)[0].table.tbody\n",
    "            values['price'] = t1.find_all('table')[0].tbody.tr.find_all('td')[1].text.strip()[:-1]\n",
    "            break\n",
    "        except:\n",
    "            offset += 1\n",
    "            if offset == 20:\n",
    "                break\n",
    "    if offset == 20:\n",
    "        continue\n",
    "\n",
    "    pattern = r'(blue|red|orange|yellow|green|brown|purple|pink) dye'\n",
    "\n",
    "    for line in fruit.find_all(string = re.compile('dye')):\n",
    "        if match := re.search(pattern, line):\n",
    "            values['color'] = match.group(1)\n",
    "            break\n",
    "\n",
    "    fruitdata.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegraw = []\n",
    "for veg in veglist:\n",
    "    vegraw.append((veg, BeautifulSoup(requests.get(f'https://stardewvalleywiki.com/{fruit.replace(\" \", \"_\")}').text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegdata = []\n",
    "for name, veg in vegraw:\n",
    "    values = {}\n",
    "    values['name'] = name\n",
    "\n",
    "    table = veg.find_all('table', {'id': 'infoboxtable'})[0].tbody\n",
    "    rows = table.find_all('tr', recursive = False)\n",
    "\n",
    "    offset = 0\n",
    "    while True:\n",
    "        try:\n",
    "            t1 = rows[9 + offset].find_all('td', recursive = False)[0].table.tbody\n",
    "            values['price'] = t1.find_all('table')[0].tbody.tr.find_all('td')[1].text.strip()[:-1]\n",
    "            break\n",
    "        except:\n",
    "            offset += 1\n",
    "            if offset == 20:\n",
    "                break\n",
    "    if offset == 20:\n",
    "        continue\n",
    "\n",
    "    pattern = r'(blue|red|orange|yellow|green|brown|purple|pink|pale violet|white) dye'\n",
    "\n",
    "    for line in veg.find_all(string = re.compile('dye')):\n",
    "        if match := re.search(pattern, line):\n",
    "            values['color'] = match.group(1)\n",
    "            break\n",
    "\n",
    "    vegdata.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishraw = []\n",
    "for fish in fishlist:\n",
    "    fishraw.append((fish, BeautifulSoup(requests.get(f'https://stardewvalleywiki.com/{fish.replace(\" \", \"_\")}').text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishdata = []\n",
    "# scorpion carp not actually legendary but needs the same adjustment\n",
    "legendaries = ['Legend', 'Crimsonfish', 'Angler', 'Glacierfish', 'Mutant Carp', 'Scorpion Carp'] \n",
    "for name, fish in fishraw:\n",
    "    values = {}\n",
    "\n",
    "    leg = 0\n",
    "    if name in legendaries:\n",
    "        leg = 1\n",
    "\n",
    "    table = fish.find_all('table', {'id': 'infoboxtable'})[0].tbody\n",
    "    rows = table.find_all('tr', recursive = False)\n",
    "\n",
    "    values['name'] = name\n",
    "    values['location'] = '|'.join([a.text.strip() for a in rows[4].find_all('td', recursive = False)[1].find_all('a')])\n",
    "    if values['location'] == '':\n",
    "        values['location'] = rows[4].find_all('td', recursive = False)[1].text.strip()\n",
    "    values['time'] = rows[5].find_all('td', recursive = False)[1].text.strip()\n",
    "    values['time'] = re.match(r'.*(\\d{1,2}[ap]m [-\\u2013] \\d{1,2}[ap]m|Any).*', values['time']).group(1)\n",
    "    values['weather'] = '|'.join([a.text.strip() for a in rows[7].find_all('td', recursive = False)[1].find_all('a')])\n",
    "    if values['weather'] == '':\n",
    "        values['weather'] = rows[7].find_all('td', recursive = False)[1].text.strip()\n",
    "    values['size'] = f'{rows[10 + leg].find_all(\"td\", recursive = False)[1].text.strip()} in.'\n",
    "\n",
    "    \n",
    "    # Season needs some extra work for multiple seasons\n",
    "    seasons = [a.text for a in rows[6].find_all('td', recursive = False)[1].find_all('a')]\n",
    "    stops = ['Ginger Island', 'Secret Woods', 'Rain Totem']\n",
    "    for stop in stops:\n",
    "        if stop in seasons:\n",
    "            seasons = seasons[:seasons.index(stop)]\n",
    "\n",
    "    if name == 'Tuna':\n",
    "        with open('scratch.html', 'w') as fout:\n",
    "            fout.write(rows.__str__())\n",
    "    values['seasons'] = '|'.join(seasons)\n",
    "\n",
    "    # Price needs... even more\n",
    "    pricetable = (rows[13 + leg].find_all('td', recursive = False)[0].table.tbody # Get main price chart\n",
    "        .find_all('tr', recursive = False)[2] # Skip over headers\n",
    "        .find_all('table')[0].tbody) # Get weird internal table that actually holds price values\n",
    "\n",
    "    pricerows = pricetable.find_all('tr', recursive = False)\n",
    "\n",
    "    values['price'] = pricerows[0].find_all('td')[1].text.strip()[:-1]\n",
    "\n",
    "    fishdata.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "OUTPUT_DIR = 'stardewvalley'\n",
    "\n",
    "if os.path.exists(OUTPUT_DIR) and os.path.isfile(OUTPUT_DIR):\n",
    "    os.remove(OUTPUT_DIR)\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'fish.csv'), 'w') as fout:\n",
    "    writer = csv.DictWriter(fout, fieldnames = list(fishdata[0].keys()))\n",
    "    writer.writeheader()\n",
    "    writer.writerows(fishdata)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'fruit.csv'), 'w') as fout:\n",
    "    writer = csv.DictWriter(fout, fieldnames = list(fruitdata[0].keys()))\n",
    "    writer.writeheader()\n",
    "    writer.writerows(fruitdata)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'veg.csv'), 'w') as fout:\n",
    "    writer = csv.DictWriter(fout, fieldnames = list(vegdata[0].keys()))\n",
    "    writer.writeheader()\n",
    "    writer.writerows(vegdata)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
